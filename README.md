Api Work - An introduction to APIs. As always, consult the documentation before trying to make API calls. Here, we are working with the World Bank. Construct a response through a request.get with the URL in a .json(). It is advisable to print the jsonified response using .dumps(). The goal is to get a list of each Lending type. Traverse the index and use a list comprehension to extract the necessary values. Now that we have a list of the lending types, we create an empty array and construct a loop that queries the World Bank data using each lending type in the query. In the response, there is an array which has a key-value pair which contains the total amount of countries that use that specific lending type. Append this value to the array.

Twitter Sentiment - This is an introduction to Vader Sentiment Analysis and Tweepy. After importing depencies and the sentiment analyzer, the next step is to instantiate a Tweepy API call. We create a list of the 5 twitter handles we wish to observe and loop through each, pulling the last 100 tweets from each account and create a DataFrame that houses all of them. We assign each tweet an index value 1-100 per handle. This process facilitates the creation of the the plot points. The points are then put into a scatter graph. The last step is to get the average compound score for each Handle by using a groupby.mean(). These values are inserted into a bar graph.

Weather & Vacation - A more involved exercise which features multiple API calls (OpenWeather / Google Maps), Graphing and Mapping. The ultimate goal is to analyze weather of randomly generating cities and then to create a 'short-list' of cities with perfect temperature and find hotels in those cities. The initial goal is to generate a robust list of cities by randomly generating longitude and latitude cooridnates using numpy. Using citipy, we identify the nearest city to each set of coordinates and create a dataFrame that will be populated through our OpenWeather API call. Once our dataFrame has been fully-populated, we drop all the rows without values and then filter out cities with Humidity of 100%. We then have a robust DataFrame that can be plotted in a multitude in ways. The first section measures latitude against other collected datapoints for each city, such as Wind Speed, Humidity, Temperature and Cloudiness. The DataFrame is then broken down into Northern vs. Southern Hemisphere cities. Using scipy stats, we are able to calculate the linear regression as well as the correlation coefficient for Northern and Southern Hemisphere cities to examine the relationship between Latitude and the same collected DataPoints. All graphs are exported as PNGs. The second stage of our project is to create a 'short-list' of cities for prospective Vacation destinations. We first create a Google Maps with a Heat Layer that measures city Humidity. This gives the user a global view of Humdity hotspots from the city DataFrame create. We then create a new dataFrame that collects only cities with idyllic weather conditions (Weather between 70-80 degrees, 0 Cloudiness, Windspeed less than 10 mph). Using Google Maps API, we find a hotel within 5000 meters of each location and add the top result to the dataFrame. The hotel addresses are then added to our orignal heatmap.
